<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/hehuihui1994.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/hehuihui1994.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/hehuihui1994.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/hehuihui1994.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/hehuihui1994.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/hehuihui1994.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/hehuihui1994.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="主题模型," />










<meta name="description" content="主题模型​    阅读的论文[1]中将主题模型与神经网络相结合进行情绪分类（topic-level emotion classification），关于主题模型的部分论文中的介绍过于简单。根据论文[1]中提到的相关文献学习了用Word2Vec、Replicated Softmax Machine得到话题分布。">
<meta property="og:type" content="article">
<meta property="og:title" content="受限玻尔兹曼机">
<meta property="og:url" content="https://github.com/hehuihui1994/hehuihui1994.github.io/2017/10/12/受限玻尔兹曼机/index.html">
<meta property="og:site_name" content="何烩烩的博客">
<meta property="og:description" content="主题模型​    阅读的论文[1]中将主题模型与神经网络相结合进行情绪分类（topic-level emotion classification），关于主题模型的部分论文中的介绍过于简单。根据论文[1]中提到的相关文献学习了用Word2Vec、Replicated Softmax Machine得到话题分布。">
<meta property="og:image" content="http://oc3xgjy1i.bkt.clouddn.com/20170830-4.png">
<meta property="og:image" content="http://oc3xgjy1i.bkt.clouddn.com/20170831-1.png">
<meta property="og:image" content="http://oc3xgjy1i.bkt.clouddn.com/20170830-3.png">
<meta property="og:image" content="http://oc3xgjy1i.bkt.clouddn.com/20170830-2.png">
<meta property="og:updated_time" content="2017-10-12T03:17:07.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="受限玻尔兹曼机">
<meta name="twitter:description" content="主题模型​    阅读的论文[1]中将主题模型与神经网络相结合进行情绪分类（topic-level emotion classification），关于主题模型的部分论文中的介绍过于简单。根据论文[1]中提到的相关文献学习了用Word2Vec、Replicated Softmax Machine得到话题分布。">
<meta name="twitter:image" content="http://oc3xgjy1i.bkt.clouddn.com/20170830-4.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/hehuihui1994.github.io/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/hehuihui1994/hehuihui1994.github.io/2017/10/12/受限玻尔兹曼机/"/>





  <title>受限玻尔兹曼机 | 何烩烩的博客</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/hehuihui1994.github.io/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">何烩烩的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/hehuihui1994.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/hehuihui1994.github.io/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/hehuihui1994.github.io/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/hehuihui1994/hehuihui1994.github.io/hehuihui1994.github.io/2017/10/12/受限玻尔兹曼机/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="何烩烩">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/hehuihui1994.github.io/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="何烩烩的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">受限玻尔兹曼机</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-12T11:11:09+08:00">
                2017-10-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/hehuihui1994.github.io/categories/academic/" itemprop="url" rel="index">
                    <span itemprop="name">学术</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="主题模型"><a href="#主题模型" class="headerlink" title="主题模型"></a>主题模型</h1><p>​    阅读的论文[1]中将主题模型与神经网络相结合进行情绪分类（topic-level emotion classification），关于主题模型的部分论文中的介绍过于简单。根据论文[1]中提到的相关文献学习了用Word2Vec、Replicated Softmax Machine得到话题分布。</p>
<a id="more"></a>
<h2 id="1-Word2vec"><a href="#1-Word2vec" class="headerlink" title="1 Word2vec"></a>1 Word2vec</h2><p>​    论文[1]中没有给出如何使用word2vec得到话题分布，但是提到了两篇文献[2-3]，文献[2]采用average-    pooling，也就是将词向量相加取平均（<strong>取平均值法</strong>）。文献[3]提出采用聚类方法（<strong>聚类法</strong>），该篇论文在网络上没有搜索到。使用使用word2vec得到话题分布的聚类方法，一般将word2vec得到的词向量进行聚类，当文档中的某个特征项属于类别$c_i$时，就在该类别$c_i$所在的维度向量上加1，这样就可以得到每篇文档在不同类别下的分布表示（话题分布）[4]。</p>
<h2 id="2-Replicated-Softmax-Machine"><a href="#2-Replicated-Softmax-Machine" class="headerlink" title="2 Replicated Softmax Machine"></a>2 Replicated Softmax Machine</h2><p>​    RSM (Replicated Softmax Machine) [5]实质是一个RBM（受限玻尔兹曼机）模型。作者在文中称为每一篇文本建立一个RBM，有点言过其实了。实际上，每个文章的长度不同、输入节点数目不同，网络结构显得不同。</p>
<h3 id="2-1-受限玻尔兹曼机-Restricted-Boltzmann-Machine-RBM"><a href="#2-1-受限玻尔兹曼机-Restricted-Boltzmann-Machine-RBM" class="headerlink" title="2.1 受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)"></a>2.1 受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)</h3><p>​    受限玻尔兹曼机(Restricted Boltzmann Machine,简称RBM)是由Hinton和Sejnowski于1986年提出的一种<strong>生成式</strong>随机神经网络(generative stochastic neural network)，该网络由一些可见单元(visible unit)和一些隐藏单元(hidden unit)构成，<strong>可见变量和隐藏变量都是二元变量</strong>，即其状态取{0,1}。</p>
<p>​    RBM实质上是一种无监督机器学习模型，通过对输入数据进行重构，从而有效地提取数据特征。考虑输入特征为$\textbf{X}$,以及转化的特征$\textbf{Y}$。RBM的任务是找到$\textbf{X} \rightarrow \textbf{Y}$的映射关系。</p>
<p>​    RBM整个网络是个二分（概率）图，层内变量无连接，层间变量是全连接，如下图所示：</p>
<p><img src="http://oc3xgjy1i.bkt.clouddn.com/20170830-4.png" alt="20170830-4"></p>
<p>​    上图所示的RBM含有3个可见单元(构成一个向量v)和4个隐藏单元(构成一个向量h)，W是一个3*4的矩阵，表示可见单元和隐藏单元之间的边的权重。</p>
<p><strong>（1）RBM的学习目标-最大化似然(Maximizing likelihood)</strong></p>
<pre><code>RBM是一种基于能量(Energy-based)的模型，其可见变量v和隐藏变量h的联合配置(joint configuration)的能量为：
</code></pre><p>$$<br>E(\textbf{v}, \textbf{h}; \theta) = -\sum_{ij}W_{ij}v_ih_j - \sum_{i}b_iv_i - \sum_{j}a_jh_j \tag{1}<br>$$<br>其中，$\theta$是RBM的参数，$\theta = \{W, a, b\}$, W为可见单元和隐藏单元之间的边的权重，b和a分别为可见单元和隐藏单元的偏置(bias)。</p>
<p>​    有了v和h的联合配置的能量之后，我们就可以得到v和h的联合概率：<br>$$<br>P(\textbf{v}, \textbf{h}) = \frac{1}{Z}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{2}<br>$$</p>
<p>$$<br>Z = \sum_{\textbf{v}}\sum_{\textbf{h}}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{3}<br>$$</p>
<p>​    其中，Z为归一化因子，也称为配分函数(partition function)。由公式（2）可得：<br>$$<br>P(\textbf{v}) = \frac{1}{Z}\sum_{\textbf{h}}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{4}<br>$$<br>​    将公式（1）代入公式(4)得：<br>$$<br>\begin{align}<br>P(\textbf{v}) &amp;=\frac{1}{Z}\sum_{\textbf{h}}exp(\sum_{ij}W_{ij}v_ih_j + \sum_{i}b_iv_i + \sum_{j}a_jh_j ) \\<br>&amp; = \frac{1}{Z}\sum_{\textbf{h}}exp(\sum_{i=1}^{D}\sum_{j=1}^{F}W_{ij}v_ih_j + \sum_{i=1}^{D}b_iv_i + \sum_{j=1}^{F}a_jh_j ) \\<br>&amp; = \frac{1}{Z}\sum_{\textbf{h}}exp[\textbf{v}^TW\textbf{h} + \textbf{a}^T\textbf{h} + \textbf{b}^T\textbf{v} ]<br>\end{align} \tag{4}<br>$$<br>​    其中，D为可见单元数，F为隐藏单元数。根据极大似然准则，定义<strong>目标函数</strong>如下：<br>$$<br>L(\theta) =\Pi_{n=1}^{N}P(\textbf{v}^{(n)}) \tag{5}<br>$$<br>​    N为样本数，两边同时log，得到：<br>$$<br>l(\theta) = \sum_{n=1}^{N}logP(\textbf{v}^{(n)}) \tag{6}<br>$$<br><strong>(2)RBM的学习方法-CD(Contrastive Divergence，对比散列)</strong></p>
<p>​    通过随机梯度下降(stichastic gradient descent)求得参数。详细推导过程见<a href="http://blog.csdn.net/xbinworld/article/details/45128733" target="_blank" rel="external">这里</a>。<br>$$<br>\begin{align}<br>\frac{\partial l{(\theta)}}{\partial W_{ij}} &amp;=  \frac{\partial}{\partial W_{ij}}log(\sum_{\textbf{h}}exp[\textbf{v}^{(n)T}W\textbf{h} + \textbf{a}^T\textbf{h} + \textbf{b}^T\textbf{v}^{(n)} ])  - \frac{\partial}{\partial W_{ij}}logZ\\<br>&amp;= \frac{\partial}{\partial W_{ij}}log(\sum_{\textbf{h}}exp(\sum_{ij}W_{ij}v_i^{(n)}h_j + \sum_{i}b_iv_i^{(n)} + \sum_{j}a_jh_j )  - \\&amp;\frac{\partial}{\partial W_{ij}}log \sum_{\textbf{v}}\sum_{\textbf{h}}exp(\sum_{ij}W_{ij}v_ih_j + \sum_{i}b_iv_i + \sum_{j}a_jh_j )\\<br>&amp; = P(h_j =1 | \textbf{v}^{(n)})v_i^{(n)} - \sum_{ \textbf{v}}P(\textbf{v})P(h_j =1|\textbf{v})v_i<br>\\<br>&amp; = P_{data}(v_ih_j) - P_{model}(v_ih_j)<br>\end{align}<br>\tag{7}<br>$$<br>​    式（7）中，前者比较好算，但是后者计算量非常大(基本不可解)。为解决该计算问题，Hinton等人提出了一种高效的学习算法-CD(Contrastive Divergence)，其基本思想如下图所示：</p>
<p><img src="http://oc3xgjy1i.bkt.clouddn.com/20170831-1.png" alt="20170831-1"></p>
<p>​    首先根据数据v来得到h的状态，然后通过h来重构(Reconstruct)可见向量v1，然后再根据v1来生成新的隐藏向量h1。因为RBM的特殊结构(层内无连接，层间有连接)， 所以在给定v时，各个隐藏单元hj的激活状态之间是相互独立的，反之，在给定h时，各个可见单元的激活状态vi也是相互独立的，亦即：<br>$$<br>P(\textbf{h}|\textbf{v}) = \Pi_{j}P(h_j | \textbf{v}) \tag{8}<br>$$<br>其中，<br>$$<br>\begin{align}<br>P(h_j = 1 | \textbf{v}) &amp;= sigmoid(\sum_iW_{ij}v_i + a_j)\\<br>&amp; = \frac{1}{1+exp(-\sum_iW_{ij}v_i - a_j)}<br>\end{align}<br>\tag{9}<br>$$<br>类似地：<br>$$<br>P(\textbf{v}|\textbf{h}) = \Pi_{i}P(v_i | \textbf{h}) \tag{10}<br>$$</p>
<p>$$<br>\begin{align}<br>P(v_i = 1 | \textbf{h}) &amp;= sigmoid(\sum_jW_{ij}h_j + b_i)\\<br>&amp; = \frac{1}{1+exp(-\sum_jW_{ij}h_j - b_i)}<br>\end{align}<br>\tag{11}<br>$$</p>
<p>​    重构的可见向量v1和隐藏向量h1就是对P(v,h)的一次抽样，多次抽样得到的样本集合可以看做是对P(v,h)的一种近似，使得式子(7)的计算变得可行。</p>
<p> <strong>（3）RBM的参数的学习算法</strong></p>
<p>​    1.取一个样本数据，把可见变量的状态设置为这个样本数据。随机初始化W，a，b。</p>
<p>​    2.根据式子公式（8）来更新隐藏变量的状态，亦即$h_j$以$P(h_j=1|v)$的概率设置为状态1，否则为0。然后对于每个边$v_ih_j$，计算$P_{data}(v_ih_j)=v_i*h_j$(注意，$v_i$和$h_j$的状态都是取{0,1})。</p>
<p>​    3.根据h的状态和公式（10）来重构v1，并且根据v1和公式(8)来求得h1，计算$P_{model}(v1_ih1_j)=v1_i*h1_j$。</p>
<p>​    4.更新边$v_ih_j$的权重$W_{ij}$为$W_{ij}=W_{ij}-\alpha*(P_{data}(v_ih_j)-P_{model}(v1_ih1_j))$。</p>
<p>​    5.更新偏置项$a_j = a_j - \alpha(h_j - h1_j)$， $b_i = b_i - \alpha(v_i - v1_i)$。</p>
<p>​    6.取下一个数据样本，重复1-5的步骤。</p>
<p>​    7.以上过程迭代K次。</p>
<h3 id="2-2-RSM"><a href="#2-2-RSM" class="headerlink" title="2.2 RSM"></a>2.2 RSM</h3><p>​    上一章节中介绍的标准RBM模型的可见变量和隐藏变量都是二元变量。实际上，RBM的可见变量除了可以是二元变量，还可以是<strong>多项式</strong>变量，但是隐藏层一直都是伯努利变量。在多项式可见变量的情况下，可见单元的logistic被替换成softmax函数,即：<br>$$<br>\begin{align}<br>P(v_i = 1 | \textbf{h}) &amp;= sigmoid(\sum_jW_{ij}h_j + b_i)\\<br>&amp; = \frac{1}{1+exp(-\sum_jW_{ij}h_j - b_i)}<br>\end{align}<br>\tag{11}<br>$$<br>变成：<br>$$<br>\begin{align}<br>P(v_i^{k} = 1 | \textbf{h}) &amp;= softmax(\sum_jW_{ij}^{k}h_j + b_i^{k})\\<br>&amp;= \frac{exp(\sum_jW_{ij}^{k}h_j + b_i^{k})}{\sum_{k’ = 1}^{K}exp(\sum_jW_{ij}^{k’}h_j + b_i^{k’})}<br>\end{align} \tag{12}<br>$$<br>其中，K表示可见单元变量的离散值个数，这种RBM模型被用于主题模型中。</p>
<p>​    论文[5]对RSM模型进行了介绍，它有两层网络，如图：</p>
<p><img src="http://oc3xgjy1i.bkt.clouddn.com/20170830-3.png" alt="20170830-1"></p>
<p><img src="http://oc3xgjy1i.bkt.clouddn.com/20170830-2.png" alt="20170830-1"></p>
<p>​    第一张图中，输入层各个节点代表词语（图中输入层有三个词语），中间隐含层的节点是<strong>0-1</strong>随机变量，表示文本topic。整体上，沿用RBM的模型，训练算法也用CD-k算法。不过，与标准RBM有两点不同：</p>
<ul>
<li>1）<strong>输入层的节点个数不确定。</strong>  节点个数由一篇文章的词数决定，而文章长度不确定，词数也不确定；</li>
<li>2）<strong>网络权重仅仅由隐含层决定。</strong>  所有输入层节点与某一个隐含层节点的关联权重都相同。</li>
</ul>
<p>​        第二张图是另一种解释方式，即只有一个输入节点，与各个隐含节点相关联。这个输入节点表示一个随机变量，该随机变量sample N次（N是文本长度）。</p>
<p><strong>(1)RSM的学习目标-最大化似然(Maximizing likelihood)</strong></p>
<p>​    令$\textbf{v} \in \{1, … , K\}^D$,其中K为词表大小，<strong>D为文档大小</strong>。令$\textbf{h} \in \{0, 1\}^F$为隐层话题特征，F为隐藏层节点数。</p>
<p>​    令𝐕为K × D的二维二值矩阵，$v_i^k =1 $当且仅当文档第𝑖个可见单元为单词𝑘，显然𝐕的每一行只有一个为 1。</p>
<p>​    定义该模型的能量为：<br>$$<br>\begin{align}<br>E(\textbf{v}, \textbf{h}; \theta) &amp;= -\sum_{ij}\sum_{k=1}^{K}W_{ij}^{k}v_i^{k}h_j - \sum_{i}\sum_{k=1}^{K}b_i^{k}v_i^{k} - D\sum_{j}a_jh_j \tag{13}\\<br>\end{align}<br>$$<br>其中，$\theta$是RSM的参数，$\theta = \{W, a, b\}$, W为可见单元的单词和隐藏单元之间连接的权重，$b_i^k$表示可见单元i取值为第k个词时的偏置项，a为隐藏单元的偏置。令$\hat{v}^{k} = \sum_{i=1}^{D}v_i^k$表示第k个单词出现在文档中的次数。在RSM中，  所有输入层节点与某一个隐含层节点的关联权重都相同。因此，该模型的能量具有更为简单的形式：<br>$$<br>E(\textbf{v}, \textbf{h}; \theta) = -\sum_{j}\sum_{k=1}^{K}W_{j}^{k}\hat{v}^{k}h_j - \sum_{k=1}^{K}b^{k}\hat{v}^{k} - D\sum_{j}a_jh_j \tag{14}<br>$$<br><strong>(2)RSM的学习方法-CD(Contrastive Divergence，对比散列)</strong><br>$$<br>P(\textbf{v}, \textbf{h}) = \frac{1}{Z}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{15}<br>$$</p>
<p>$$<br>Z = \sum_{\textbf{v}}\sum_{\textbf{h}}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{16}<br>$$</p>
<p>$$<br>P(\textbf{v}) = \frac{1}{Z}\sum_{\textbf{h}}exp(- E(\textbf{v}, \textbf{h}; \theta)) \tag{17}<br>$$</p>
<p>$$<br>L(\theta) =\Pi_{n=1}^{N}P(\textbf{v}^{(n)}) \tag{17}<br>$$</p>
<p>$$<br>l(\theta) = \sum_{n=1}^{N}logP(\textbf{v}^{(n)}) \tag{18}<br>$$</p>
<p>采用随机梯度下降，<br>$$<br>\begin{align}<br>\frac{\partial l{(\theta)}}{\partial W_{j}^{k}} &amp;= \frac{\partial }{\partial W_{j}^{k}}log\frac{1}{Z}\sum_{\textbf{h}}exp(- E(\textbf{v}, \textbf{h}; \theta)) \\<br>&amp; = \frac{\partial}{\partial W_{j}^{k}}log(\sum_{\textbf{h}}exp(\sum_{j}\sum_{k=1}^{K}W_{j}^{k}\hat{v}^{k}h_j +\sum_{k=1}^{K}b^{k}\hat{v}^{k} + D\sum_{j}a_jh_j )  - \frac{\partial}{\partial W_{j}^{k}}logZ\\<br>&amp; =  \frac{\partial}{\partial W_{j}^{k}}log(\sum_{\textbf{h}}exp(\sum_{j}\sum_{k=1}^{K}W_{j}^{k}\hat{v}^{k}h_j +\sum_{k=1}^{K}b^{k}\hat{v}^{k} + D\sum_{j}a_jh_j )- \\<br>&amp; \frac{\partial}{\partial W_{j}^{k}}log(\sum_{\textbf{v}}\sum_{\textbf{h}}exp(\sum_{j}\sum_{k=1}^{K}W_{j}^{k}\hat{v}^{k}h_j +\sum_{k=1}^{K}b^{k}\hat{v}^{k} + D\sum_{j}a_jh_j )\\<br>&amp; =P_{data}{ (\hat{v}^{k}h_j)}   - P_{model}(\hat{v}^{k}h_j)<br>\end{align} \tag{19}<br>$$<br>状态转移的条件概率为：<br>$$<br>\begin{align}<br>P(v_i^{k} = 1 | \textbf{h}) &amp;= softmax(\sum_jW_{j}^{k}h_j + b^{k})\\<br>&amp;= \frac{exp(\sum_jW_{j}^{k}h_j + b^{k})}{\sum_{k’ = 1}^{K}exp(\sum_jW_{j}^{k’}h_j + b^{k’})}<br>\end{align} \tag{20}<br>$$</p>
<p>$$<br>\begin{align}<br>P(h_j = 1 | \textbf{v}) &amp;= sigmoid(\sum_kW_{j}^{k}\hat{v}^k + Da_j)\\<br>&amp; = \frac{1}{1+exp(-\sum_kW_{j}^{k}\hat{v}^k - Da_j)}<br>\end{align}<br>\tag{21}<br>$$</p>
<p> <strong>(3)RSM的参数的学习算法</strong></p>
<p>​    1.取一个样本数据，把可见变量的状态设置为这个样本数据。随机初始化W，a，b。</p>
<p>​    2.根据式子公式（21）来更新隐藏变量的状态，亦即$h_j$以$P(h_j=1|v)$的概率设置为状态1，否则为0。然后计算$P_{data}{ (\hat{v}^{k}h_j)} = \hat{v}^{k}h_j$。</p>
<p>​    3.根据h的状态和公式（20）来重构v1，并且根据v1和公式(20)来求得h1，计算$P_{model}(\hat{v1}^{k}h1_j)=\hat{v1}^{k}h1_j$。</p>
<p>​    4.更新权重$W_{j}^{k}$，$W_{j}^{k}=W_{j}^{k}-\alpha*(P_{data}{ (\hat{v}^{k}h_j)} -P_{model}(\hat{v1}^{k}h1_j)$。</p>
<p>​    5.更新偏置项$a_j = a_j - \alpha D(h_j - h1_j)$， $b^{k} = b^{k} - \alpha(\hat{v}^{k} - \hat{v1}^{k})$。</p>
<p>​    6.取下一个数据样本，重复1-5的步骤。</p>
<p>​    7.以上过程迭代K次。</p>
<p>​    RBM：$[0 1 1 0 0 1]_{词表}$<br>​    RSM:   $[0 3 1 0 0 1]_{词表}$</p>
<p>​    RBM只关心词k是否在文档中出现，RSM关心词k在文档中出现的次数。</p>
<h2 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3 参考资料"></a>3 参考资料</h2><p>【1】Li X, Rao Y, Xie H, et al. Bootstrapping Social Emotion Classification with Semantically Rich Hybrid Neural Networks[J]. IEEE Transactions on Affective Computing, 2017.(cite:0)</p>
<p>【2】Chao Xing, Dong Wang, Xuewei Zhang, and Chao Liu. Document classification with distributions of word vectors. In Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, pages 1–5. IEEE, 2014. (cite:20)</p>
<p>【3】Yuan Y, He L, Peng L, et al. A new study based on word2vec and cluster for document categorization [J].  Journal of Computational Information Systems, 2014, 10(21): 9301-9308.(cite:11)</p>
<p>【4】冯贵川. 基于 Word2vec 的文本建模及分类研究[D]. 深圳大学, 2016. (cite:0)</p>
<p>【5】Geoffrey E. Hinton and Ruslan R. Salakhutdinov. Replicated softmax: an undirected topic model. In Advances in Neural Information Processing Systems, pages 1607– 1614, 2009.（cite:271）</p>
<p>【6】<a href="https://zhuanlan.zhihu.com/p/24989699" target="_blank" rel="external">受限玻尔兹曼机知识概要（RBM)</a></p>
<p>【7】<a href="http://www.cnblogs.com/kemaswill/p/3203605.html" target="_blank" rel="external">受限玻尔兹曼机(Restricted Boltzmann Machine, RBM) 简介</a></p>
<p>【8】<a href="http://blog.csdn.net/xceman1997/article/details/11383741" target="_blank" rel="external">Deep Learning 学习笔记： Modeling Documents with a Deep Boltzmann Machine</a></p>
<p>【9】<a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine" target="_blank" rel="external">维基百科：Restricted Boltzmann machine</a></p>
<p>【10】王琳. 短文本文档建模及查询扩展方法研究[D]. 大连理工大学, 2016.(cite:0)</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/hehuihui1994.github.io/tags/主题模型/" rel="tag"># 主题模型</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/hehuihui1994.github.io/2017/10/10/jupyter-notebook/" rel="next" title="jupyter notebook ">
                <i class="fa fa-chevron-left"></i> jupyter notebook 
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/hehuihui1994.github.io/2017/10/13/Kleinberg/" rel="prev" title="Kleinberg">
                Kleinberg <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">何烩烩</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/hehuihui1994.github.io/archives">
              
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">Kategorien</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">Tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#主题模型"><span class="nav-number">1.</span> <span class="nav-text">主题模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Word2vec"><span class="nav-number">1.1.</span> <span class="nav-text">1 Word2vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Replicated-Softmax-Machine"><span class="nav-number">1.2.</span> <span class="nav-text">2 Replicated Softmax Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-受限玻尔兹曼机-Restricted-Boltzmann-Machine-RBM"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-RSM"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 RSM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-参考资料"><span class="nav-number">1.3.</span> <span class="nav-text">3 参考资料</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">何烩烩</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/hehuihui1994.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/hehuihui1994.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/hehuihui1994.github.io/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/hehuihui1994.github.io/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/hehuihui1994.github.io/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/hehuihui1994.github.io/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
